{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import feature_column\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_size=1000\n",
    "test_frac = 0.1\n",
    "input_size = 16\n",
    "output_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoremaker():\n",
    "    #empty scores represent the subjects that the student doesn't take\n",
    "    emptyScores = np.random.randint(low = 0, high = output_size, size=(3))        \n",
    "    \n",
    "    #randomly generate 2 sets of results. For different schools, scale the result accordingly\n",
    "    scores = np.random.randint(low = 50, high = 90, size=(output_size))\n",
    "    scores = scores + np.random.randint(low = -10, high = 10, size=(output_size))\n",
    "    scores2 = np.random.randint(low = 50, high = 90, size=(output_size))\n",
    "    scores2 = scores2 + np.random.randint(low = -10, high = 10, size=(output_size))\n",
    "    \n",
    "    #generate 2 values, 1 for humanities-related activities and one for science activities. More activities = higher score\n",
    "    activities = np.random.randint(low = 0, high = 10, size = (2))\n",
    "    \n",
    "    #generate fake labels for each listing.\n",
    "    scoreLabels = (scores + scores2) / 2\n",
    "    \n",
    "    #add activity score to labels for each subject\n",
    "    for i in range(output_size):\n",
    "        if(i < 4): scoreLabels[i] += activities[0]\n",
    "        else: scoreLabels[i] += activities[1]\n",
    "\n",
    "    scoreLabels = (scoreLabels - 40) / 60\n",
    "    \n",
    "    #make subjects empty\n",
    "    for i in emptyScores:\n",
    "        scores[i] = 0\n",
    "        scores2[i] = 0\n",
    "        scoreLabels[i] = 0\n",
    "        \n",
    "    return scoreLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataMaker():\n",
    "    #make some fake scores and use signed difference as a feature\n",
    "    teacherscores = scoremaker()\n",
    "    studentscores = scoremaker()\n",
    "    scoresdiff = teacherscores - studentscores\n",
    "    \n",
    "    #label is closely related to how much better a teacher is than a student.\n",
    "    #also have to penalize for being too good.\n",
    "    #right now I'm using a piecewise method to penalize:\n",
    "    #if  diff > 0.5 then diff = 1 - 0.5\n",
    "    label = np.array(scoresdiff)\n",
    "    \n",
    "    for i in range(output_size):\n",
    "        if label[i] > 0.5:\n",
    "            label[i] = 1 - label[i]\n",
    "\n",
    "    #4 bit mbti     \n",
    "    teacherpersonality = np.random.randint(low = 0, high = 2, size = (4))    \n",
    "    studentpersonality = np.random.randint(low = 0, high = 2, size = (4))\n",
    "    crosspersonality = 1 - np.bitwise_xor(teacherpersonality, studentpersonality)\n",
    "    \n",
    "    bitcount = np.sum(crosspersonality)\n",
    "    label = label + ((bitcount / 4 - 0.5) * 0.1)\n",
    "\n",
    "    #4 interest choices: music/art, sports, academic, humanities\n",
    "    #first 2 affect labels equally, second 2 affect only the scores for each subject\n",
    "    teacheractivities = np.random.randint(low = 0, high = 11, size = (4))\n",
    "    studentactivities = np.random.randint(low = 0, high = 11, size = (4))\n",
    "    crossactivities = np.multiply(teacheractivities, studentactivities)\n",
    "    \n",
    "    for i in range(output_size):\n",
    "        label[i] = label[i] + ((crossactivities[0] + crossactivities[1]) / 200 - 0.5) * 0.1\n",
    "        if(i < 4):\n",
    "            label[i] = label[i] + (crossactivities[2] / 100 - 0.5) * 0.1\n",
    "        else:\n",
    "            label[i] = label[i] + (crossactivities[3] / 100 - 0.5) * 0.1\n",
    "    \n",
    "    \n",
    "    #need to normalise labels to 0 to 1.\n",
    "    label = (label - np.min(label, axis = 0)) / (np.max(label, axis = 0) - np.min(label, axis = 0))\n",
    "    \n",
    "    \n",
    "    return np.concatenate((scoresdiff, crosspersonality, crossactivities, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = np.array([dataMaker() for i in range(test_data_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = keras.Input(shape=(input_size,), name=\"inputs\")\n",
    "# x = layers.Dense(20,activation='relu', name='Hidden1') (inputs)\n",
    "# # x = layers.Dense(20,activation='relu', name='Hidden2') (x)\n",
    "# # x = layers.Dense(20,activation='relu', name='Hidden3') (x)\n",
    "# # x = layers.Dense(20,activation='relu', name='Hidden4') (x)\n",
    "# # x = layers.Dense(20,activation='relu', name='Hidden5') (x)\n",
    "# outputs = layers.Dense(output_size, activation=\"relu\", name=\"predictions\")(x)\n",
    "# model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(input_size,), name=\"inputs\"))\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(output_size, activation=\"relu\", name=\"predictions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = my_data[:,:input_size]\n",
    "x_train = (x_train - np.average(x_train, axis = 0))/np.std(x_train, axis = 0)\n",
    "y_train = my_data[:,input_size:]\n",
    "x_val = x_train[(int)((1-test_frac)*test_data_size):]\n",
    "y_val = y_train[(int)((1-test_frac)*test_data_size):]\n",
    "x_train = x_train[:(int)((1-test_frac)*test_data_size)]\n",
    "y_train = y_train[:(int)((1-test_frac)*test_data_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.Adam(),\n",
    "    loss = keras.losses.mean_squared_error,\n",
    "    metrics = [keras.metrics.mean_squared_error]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3823 - mean_squared_error: 0.3823 - val_loss: 0.3587 - val_mean_squared_error: 0.3587\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3521 - mean_squared_error: 0.3521 - val_loss: 0.3384 - val_mean_squared_error: 0.3384\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3301 - mean_squared_error: 0.3301 - val_loss: 0.3213 - val_mean_squared_error: 0.3213\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3108 - mean_squared_error: 0.3108 - val_loss: 0.3035 - val_mean_squared_error: 0.3035\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2939 - mean_squared_error: 0.2939 - val_loss: 0.2867 - val_mean_squared_error: 0.2867\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2778 - mean_squared_error: 0.2778 - val_loss: 0.2711 - val_mean_squared_error: 0.2711\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2608 - mean_squared_error: 0.2608 - val_loss: 0.2552 - val_mean_squared_error: 0.2552\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2421 - mean_squared_error: 0.2421 - val_loss: 0.2378 - val_mean_squared_error: 0.2378\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2220 - mean_squared_error: 0.2220 - val_loss: 0.2185 - val_mean_squared_error: 0.2185\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2015 - mean_squared_error: 0.2015 - val_loss: 0.1988 - val_mean_squared_error: 0.1988\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1825 - mean_squared_error: 0.1825 - val_loss: 0.1819 - val_mean_squared_error: 0.1819\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1653 - mean_squared_error: 0.1653 - val_loss: 0.1669 - val_mean_squared_error: 0.1669\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1502 - mean_squared_error: 0.1502 - val_loss: 0.1541 - val_mean_squared_error: 0.1541\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1362 - mean_squared_error: 0.1362 - val_loss: 0.1426 - val_mean_squared_error: 0.1426\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1236 - mean_squared_error: 0.1236 - val_loss: 0.1315 - val_mean_squared_error: 0.1315\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1127 - mean_squared_error: 0.1127 - val_loss: 0.1215 - val_mean_squared_error: 0.1215\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1029 - mean_squared_error: 0.1029 - val_loss: 0.1125 - val_mean_squared_error: 0.1125\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0940 - mean_squared_error: 0.0940 - val_loss: 0.1045 - val_mean_squared_error: 0.1045\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0861 - mean_squared_error: 0.0861 - val_loss: 0.0972 - val_mean_squared_error: 0.0972\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0794 - mean_squared_error: 0.0794 - val_loss: 0.0905 - val_mean_squared_error: 0.0905\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0739 - mean_squared_error: 0.0739 - val_loss: 0.0846 - val_mean_squared_error: 0.0846\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0692 - mean_squared_error: 0.0692 - val_loss: 0.0796 - val_mean_squared_error: 0.0796\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0651 - mean_squared_error: 0.0651 - val_loss: 0.0754 - val_mean_squared_error: 0.0754\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0616 - mean_squared_error: 0.0616 - val_loss: 0.0718 - val_mean_squared_error: 0.0718\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0585 - mean_squared_error: 0.0585 - val_loss: 0.0686 - val_mean_squared_error: 0.0686\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0555 - mean_squared_error: 0.0555 - val_loss: 0.0656 - val_mean_squared_error: 0.0656\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0530 - mean_squared_error: 0.0530 - val_loss: 0.0628 - val_mean_squared_error: 0.0628\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0508 - mean_squared_error: 0.0508 - val_loss: 0.0601 - val_mean_squared_error: 0.0601\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0487 - mean_squared_error: 0.0487 - val_loss: 0.0579 - val_mean_squared_error: 0.0579\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0469 - mean_squared_error: 0.0469 - val_loss: 0.0558 - val_mean_squared_error: 0.0558\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0452 - mean_squared_error: 0.0452 - val_loss: 0.0542 - val_mean_squared_error: 0.0542\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0437 - mean_squared_error: 0.0437 - val_loss: 0.0523 - val_mean_squared_error: 0.0523\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0422 - mean_squared_error: 0.0422 - val_loss: 0.0504 - val_mean_squared_error: 0.0504\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0408 - mean_squared_error: 0.0408 - val_loss: 0.0488 - val_mean_squared_error: 0.0488\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0396 - mean_squared_error: 0.0396 - val_loss: 0.0477 - val_mean_squared_error: 0.0477\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0385 - mean_squared_error: 0.0385 - val_loss: 0.0462 - val_mean_squared_error: 0.0462\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0373 - mean_squared_error: 0.0373 - val_loss: 0.0449 - val_mean_squared_error: 0.0449\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0363 - mean_squared_error: 0.0363 - val_loss: 0.0437 - val_mean_squared_error: 0.0437\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0354 - mean_squared_error: 0.0354 - val_loss: 0.0424 - val_mean_squared_error: 0.0424\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0344 - mean_squared_error: 0.0344 - val_loss: 0.0413 - val_mean_squared_error: 0.0413\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0335 - mean_squared_error: 0.0335 - val_loss: 0.0405 - val_mean_squared_error: 0.0405\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0327 - mean_squared_error: 0.0327 - val_loss: 0.0395 - val_mean_squared_error: 0.0395\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0319 - mean_squared_error: 0.0319 - val_loss: 0.0385 - val_mean_squared_error: 0.0385\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0312 - mean_squared_error: 0.0312 - val_loss: 0.0376 - val_mean_squared_error: 0.0376\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0305 - mean_squared_error: 0.0305 - val_loss: 0.0369 - val_mean_squared_error: 0.0369\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0298 - mean_squared_error: 0.0298 - val_loss: 0.0361 - val_mean_squared_error: 0.0361\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0292 - mean_squared_error: 0.0292 - val_loss: 0.0356 - val_mean_squared_error: 0.0356\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0286 - mean_squared_error: 0.0286 - val_loss: 0.0349 - val_mean_squared_error: 0.0349\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0279 - mean_squared_error: 0.0279 - val_loss: 0.0341 - val_mean_squared_error: 0.0341\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0273 - mean_squared_error: 0.0273 - val_loss: 0.0333 - val_mean_squared_error: 0.0333\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0268 - mean_squared_error: 0.0268 - val_loss: 0.0328 - val_mean_squared_error: 0.0328\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0263 - mean_squared_error: 0.0263 - val_loss: 0.0323 - val_mean_squared_error: 0.0323\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0258 - mean_squared_error: 0.0258 - val_loss: 0.0317 - val_mean_squared_error: 0.0317\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0253 - mean_squared_error: 0.0253 - val_loss: 0.0311 - val_mean_squared_error: 0.0311\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0248 - mean_squared_error: 0.0248 - val_loss: 0.0305 - val_mean_squared_error: 0.0305\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0244 - mean_squared_error: 0.0244 - val_loss: 0.0302 - val_mean_squared_error: 0.0302\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0240 - mean_squared_error: 0.0240 - val_loss: 0.0297 - val_mean_squared_error: 0.0297\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.0291 - val_mean_squared_error: 0.0291\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.0287 - val_mean_squared_error: 0.0287\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0282 - val_mean_squared_error: 0.0282\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0224 - mean_squared_error: 0.0224 - val_loss: 0.0278 - val_mean_squared_error: 0.0278\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0220 - mean_squared_error: 0.0220 - val_loss: 0.0275 - val_mean_squared_error: 0.0275\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0217 - mean_squared_error: 0.0217 - val_loss: 0.0271 - val_mean_squared_error: 0.0271\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0214 - mean_squared_error: 0.0214 - val_loss: 0.0265 - val_mean_squared_error: 0.0265\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0210 - mean_squared_error: 0.0210 - val_loss: 0.0262 - val_mean_squared_error: 0.0262\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0207 - mean_squared_error: 0.0207 - val_loss: 0.0260 - val_mean_squared_error: 0.0260\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0204 - mean_squared_error: 0.0204 - val_loss: 0.0255 - val_mean_squared_error: 0.0255\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0201 - mean_squared_error: 0.0201 - val_loss: 0.0251 - val_mean_squared_error: 0.0251\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0198 - mean_squared_error: 0.0198 - val_loss: 0.0249 - val_mean_squared_error: 0.0249\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0196 - mean_squared_error: 0.0196 - val_loss: 0.0246 - val_mean_squared_error: 0.0246\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0193 - mean_squared_error: 0.0193 - val_loss: 0.0243 - val_mean_squared_error: 0.0243\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0190 - mean_squared_error: 0.0190 - val_loss: 0.0241 - val_mean_squared_error: 0.0241\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.0236 - val_mean_squared_error: 0.0236\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0185 - mean_squared_error: 0.0185 - val_loss: 0.0233 - val_mean_squared_error: 0.0233\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0231 - val_mean_squared_error: 0.0231\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0180 - mean_squared_error: 0.0180 - val_loss: 0.0228 - val_mean_squared_error: 0.0228\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0178 - mean_squared_error: 0.0178 - val_loss: 0.0225 - val_mean_squared_error: 0.0225\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0176 - mean_squared_error: 0.0176 - val_loss: 0.0222 - val_mean_squared_error: 0.0222\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0174 - mean_squared_error: 0.0174 - val_loss: 0.0220 - val_mean_squared_error: 0.0220\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0172 - mean_squared_error: 0.0172 - val_loss: 0.0217 - val_mean_squared_error: 0.0217\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.0214 - val_mean_squared_error: 0.0214\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0167 - mean_squared_error: 0.0167 - val_loss: 0.0212 - val_mean_squared_error: 0.0212\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0166 - mean_squared_error: 0.0166 - val_loss: 0.0209 - val_mean_squared_error: 0.0209\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0164 - mean_squared_error: 0.0164 - val_loss: 0.0208 - val_mean_squared_error: 0.0208\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.0206 - val_mean_squared_error: 0.0206\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.0203 - val_mean_squared_error: 0.0203\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0200 - val_mean_squared_error: 0.0200\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0199 - val_mean_squared_error: 0.0199\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.0196 - val_mean_squared_error: 0.0196\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0153 - mean_squared_error: 0.0153 - val_loss: 0.0194 - val_mean_squared_error: 0.0194\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.0194 - val_mean_squared_error: 0.0194\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.0192 - val_mean_squared_error: 0.0192\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.0190 - val_mean_squared_error: 0.0190\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0188 - val_mean_squared_error: 0.0188\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.0186 - val_mean_squared_error: 0.0186\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0184 - val_mean_squared_error: 0.0184\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.0182 - val_mean_squared_error: 0.0182\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0181 - val_mean_squared_error: 0.0181\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0179 - val_mean_squared_error: 0.0179\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.0178 - val_mean_squared_error: 0.0178\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=100,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history\n",
    "epochs = history.epoch\n",
    "hist = pd.DataFrame(history.history)\n",
    "mse = hist[\"mean_squared_error\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_the_loss_curve(epochs, mse):\n",
    "    \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Mean Squared Error\")\n",
    "\n",
    "    plt.plot(epochs, mse, label=\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.ylim([mse.min()*0.95, mse.max() * 1.03])\n",
    "    plt.show()  \n",
    "\n",
    "    print(\"Defined the plot_the_loss_curve function.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined the plot_the_loss_curve function.\n"
     ]
    }
   ],
   "source": [
    "plot_the_loss_curve(epochs, mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.9513174  0.5505337  0.49426872 0.15751073 0.7478787\n",
      " 0.7494973  0.94126946]\n",
      "[0.         1.         0.60588235 0.42941176 0.26329412 0.81623529\n",
      " 0.69270588 0.95741176]\n",
      "[0.4362934  0.81209326 0.15917256 0.974486   0.85466444 0.20295696\n",
      " 0.56858134 0.1416876 ]\n",
      "[0.43856272 1.         0.05357716 0.91979467 0.68174527 0.\n",
      " 0.57747834 0.05614373]\n",
      "[0.66771924 0.41535026 0.61536455 0.8632695  0.20826034 0.5169821\n",
      " 0.6214942  0.11701514]\n",
      "[0.65459298 0.37453323 0.63592233 1.         0.13069455 0.49477222\n",
      " 0.63480209 0.        ]\n",
      "[0.5077424  0.5983446  0.489078   0.5180359  0.34934637 0.6439826\n",
      " 0.03664984 0.8750274 ]\n",
      "[0.44222222 0.37740741 0.37740741 0.44222222 0.16666667 0.57407407\n",
      " 0.         1.        ]\n",
      "[0.63980275 0.6782388  0.9524007  0.24247617 1.1438869  0.45125765\n",
      " 1.0121616  0.        ]\n",
      "[0.70516823 0.86992716 1.         0.45369407 0.99722511 0.61567811\n",
      " 0.98855359 0.        ]\n",
      "[0.37473732 0.5789211  0.58675027 0.996779   0.69799495 0.5187575\n",
      " 0.97881234 0.        ]\n",
      "[0.55180723 0.49759036 0.47349398 0.84698795 0.6686747  0.59036145\n",
      " 1.         0.        ]\n",
      "[0.5537089  0.07967727 0.70375675 0.8889214  0.04910396 0.9997206\n",
      " 0.17192474 0.97092277]\n",
      "[0.51717949 0.05564103 0.6325641  0.95307692 0.         0.99358974\n",
      " 0.1474359  1.        ]\n",
      "[0.5857409  0.         0.2090393  1.0007985  0.87826264 0.7312814\n",
      " 0.19880399 0.80514026]\n",
      "[0.61227298 0.         0.23390204 0.88057237 1.         0.75921849\n",
      " 0.27765548 0.66290589]\n",
      "[0.6389301  0.77780396 0.9477798  0.87604266 0.         0.5555128\n",
      " 0.84478223 0.08557394]\n",
      "[0.73922591 0.77353829 0.96568762 1.         0.         0.61762284\n",
      " 0.95388416 0.19214933]\n",
      "[0.8309249  0.58313394 0.44286585 0.40219072 0.82190824 0.05841254\n",
      " 0.61343074 0.5017726 ]\n",
      "[0.99366337 0.52831683 0.44910891 0.35009901 1.         0.\n",
      " 0.56435644 0.43564356]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_train[:10])\n",
    "for i in range(10):\n",
    "    print(predictions[i])\n",
    "    print(y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"compatModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\leeji\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\leeji\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\leeji\\AppData\\Local\\Temp\\tmpr4_lkyhl\\assets\n"
     ]
    }
   ],
   "source": [
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('compatModel.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
